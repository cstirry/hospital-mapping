{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec772156-7348-4e2f-93ea-0ad05f570b9c",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214bae9-4068-4828-9cbb-4496c9170ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35c770-32c6-48bd-9148-d0c2e811cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sources\n",
    "\n",
    "# CMS - General Hospital Info\n",
    "# https://data.cms.gov/provider-data/dataset/xubh-q36u\n",
    "hosp_csv_url = 'https://data.cms.gov/provider-data/sites/default/files/resources/893c372430d9d71a1c52737d01239d47_1729022728/Hospital_General_Information.csv'\n",
    "\n",
    "# CMS - Maternal Health\n",
    "# https://data.cms.gov/provider-data/dataset/nrdb-3fcy\n",
    "mat_csv_url = \"https://data.cms.gov/provider-data/sites/default/files/resources/5a4754b088fdb10d2ae278ef215925a7_1729022763/Maternal_Health-Hospital.csv\"\n",
    "\n",
    "# ArcGIS Hospital Data API\n",
    "# https://hifld-geoplatform.hub.arcgis.com/\n",
    "hifld_url = \"https://services1.arcgis.com/Hp6G80Pky0om7QvQ/arcgis/rest/services/Hospitals_gdb/FeatureServer/0/query\"\n",
    "\n",
    "# Shapefile Paths\n",
    "# downloaded from https://www.weather.gov/gis/AWIPSShapefiles\n",
    "state_shapefile_path = 'shapefiles/s_18mr25/s_18mr25.shp'\n",
    "county_shapefile_path = 'shapefiles/c_18mr25/c_18mr25.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53af297-90cf-4e71-85e9-baeb6e761707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_csv_to_pandas(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        \n",
    "        # Load the CSV data if the request was successful\n",
    "        df = pd.read_csv(url)\n",
    "        print(f\"Data from {url} loaded successfully\", df.shape)\n",
    "        return df\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred while fetching {url}: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred while fetching {url}: {err}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def download_arcgis_api_to_pandas(url):\n",
    "    params = {\n",
    "        \"where\": \"1=1\",       \n",
    "        \"outFields\": \"*\",    \n",
    "        \"f\": \"geojson\"        \n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "        # Load GeoJSON data into a GeoDataFrame\n",
    "        gdf = gpd.read_file(response.text)\n",
    "        print(f\"Data from {url} loaded successfully\", gdf.shape)\n",
    "        return gdf\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred: {http_err}\")\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred: {err}\")\n",
    "    return None\n",
    "\n",
    "cms_mat_df = download_csv_to_pandas(mat_csv_url)\n",
    "cms_hosp_df = download_csv_to_pandas(hosp_csv_url)\n",
    "hifld_df = download_arcgis_api_to_pandas(hifld_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78de1d4-8e25-4803-87d9-026a44df5c15",
   "metadata": {},
   "source": [
    "# Create US & Maryland Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6d238f-2533-4097-a81a-a683a01a134d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70153c7e-3310-4ed7-8246-a123d37b1877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# US Heatmap\n",
    "m = folium.Map(location=[39.8283, -98.5795], zoom_start=4, tiles='Cartodb Positron')\n",
    "\n",
    "df = hifld_df\n",
    "df['lon'] = df['geometry'].apply(lambda point: point.x)\n",
    "df['lat'] = df['geometry'].apply(lambda point: point.y)\n",
    "heat_data = df[['lat', 'lon']].values.tolist()\n",
    "HeatMap(heat_data, radius=2, blur=1).add_to(m)\n",
    "\n",
    "m.save('outputs/us_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef096a-ab10-4215-b4c9-c19e4d85ace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maryland Heatmap\n",
    "m = folium.Map(location=[39.0458, -76.6413], zoom_start=8, tiles='Cartodb Positron')\n",
    "\n",
    "# Hospital data\n",
    "df = hifld_df\n",
    "md_df = df[df['STATE'] == 'MD'].copy()\n",
    "md_df['lon'] = md_df['geometry'].apply(lambda point: point.x)\n",
    "md_df['lat'] = md_df['geometry'].apply(lambda point: point.y)\n",
    "\n",
    "heat_data = md_df[['lat', 'lon']].values.tolist()\n",
    "HeatMap(heat_data, radius=8, blur=4).add_to(m)\n",
    "\n",
    "# Add Maryland boundary to the map\n",
    "states_gdf = gpd.read_file(state_shapefile_path)\n",
    "md_boundary = states_gdf[states_gdf['NAME'] == 'Maryland']\n",
    "\n",
    "folium.GeoJson(\n",
    "    md_boundary,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'none',  \n",
    "        'color': 'blue',   \n",
    "        'weight': 1        \n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "m.save('outputs/maryland_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead167de-8d87-49d0-a0d0-92fee79dd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maryland Cloropath\n",
    "m = folium.Map(location=[39.0458, -76.6413], zoom_start=8, tiles='Cartodb Positron')\n",
    "\n",
    "# Load the shapefile for US counties\n",
    "counties_gdf = gpd.read_file(county_shapefile_path)\n",
    "md_counties = counties_gdf[counties_gdf['STATE'] == 'MD']\n",
    "\n",
    "# Filter hospital data for Maryland\n",
    "md_df = df[df['STATE'] == 'MD'].copy()\n",
    "\n",
    "# Spatial join to assign counties to hospitals\n",
    "md_counties = md_counties.to_crs(epsg=4326)\n",
    "md_df = gpd.sjoin(md_df, md_counties, how=\"left\", predicate='within')\n",
    "\n",
    "# Aggregate count of hospitals by County\n",
    "hospital_count_by_county = md_df.groupby('COUNTYNAME').size().reset_index(name='HOSPITAL_COUNT')\n",
    "\n",
    "# Merge aggregated hospital count data with county shapefile\n",
    "md_counties = md_counties.merge(hospital_count_by_county, on='COUNTYNAME')\n",
    "\n",
    "# Create Choropleth map based on hospital count by county\n",
    "folium.Choropleth(\n",
    "    geo_data=md_counties,\n",
    "    data=md_counties,\n",
    "    columns=['COUNTYNAME', 'HOSPITAL_COUNT'],\n",
    "    key_on='feature.properties.COUNTYNAME',\n",
    "    fill_color='YlGn',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=0.3,\n",
    "    legend_name='Number of Hospitals by County',\n",
    "    highlight=True,\n",
    "    bins=[1, 3, 5, 10, 15, 20],\n",
    ").add_to(m)\n",
    "\n",
    "# Save or display the map\n",
    "m.save('outputs/maryland_choropleth.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2472e0c8-6010-409f-acdf-25433fc03bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maryland Dot Map\n",
    "m = folium.Map(location=[39.0458, -76.6413], zoom_start=8, tiles='Cartodb Positron')\n",
    "\n",
    "# Hospital data\n",
    "df = hifld_df\n",
    "md_df = df[df['STATE'] == 'MD'].copy()\n",
    "md_df['lon'] = md_df['geometry'].apply(lambda point: point.x)\n",
    "md_df['lat'] = md_df['geometry'].apply(lambda point: point.y)\n",
    "\n",
    "for idx, row in md_df.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['lat'], row['lon']],\n",
    "        radius=4,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_opacity=0.7,\n",
    "        popup=row.get('NAME', 'Hospital')\n",
    "    ).add_to(m)\n",
    "\n",
    "# Add Maryland boundary to the map\n",
    "states_gdf = gpd.read_file(state_shapefile_path)\n",
    "md_boundary = states_gdf[states_gdf['NAME'] == 'Maryland']\n",
    "\n",
    "folium.GeoJson(\n",
    "    md_boundary,\n",
    "    style_function=lambda feature: {\n",
    "        'fillColor': 'none',  \n",
    "        'color': 'blue',   \n",
    "        'weight': 1        \n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "m.save('outputs/maryland_marker.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd080f5-6959-44be-bc8d-4384d3f6fa98",
   "metadata": {},
   "source": [
    "# Combine Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1dff95-7295-4fc9-ac5a-e1ba0e9f1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process, fuzz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36949f98-da69-43de-823f-79eb640c6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Data\n",
    "hifld_df_md = hifld_df[hifld_df['STATE'] == 'MD']\n",
    "cms_hosp_df_md = cms_hosp_df[cms_hosp_df['State'] == 'MD']\n",
    "cms_mat_df_md = cms_mat_df[cms_mat_df['State'] == 'MD']\n",
    "\n",
    "cms_hosp_df_md = cms_hosp_df_md[['Facility ID', 'Facility Name', 'Address', 'City/Town', 'State', 'ZIP Code', 'County/Parish',\n",
    "'Hospital Type','Hospital Ownership', 'Emergency Services','Meets criteria for birthing friendly designation','Hospital overall rating']]\n",
    "\n",
    "cms_mat_df_md['Score'] = pd.to_numeric(cms_mat_df_md['Score'], errors='coerce')\n",
    "cms_mat_df_md = cms_mat_df_md.pivot_table(index=['Facility ID', 'Facility Name', 'Address', 'City/Town', 'State', 'ZIP Code'],\n",
    "                         columns='Measure Name',\n",
    "                         values='Score').reset_index()\n",
    "cms_mat_df_md.columns.name = None\n",
    "cms_mat_df_md.columns = [str(col) for col in cms_mat_df_md.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8a94d-1594-4bc1-9b58-fb36dae77372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = hifld_df_md \n",
    "df2 = cms_hosp_df_md\n",
    "df3 = cms_mat_df_md\n",
    "\n",
    "df1.rename(columns={\n",
    "    'NAME': 'Facility Name',\n",
    "    'ADDRESS': 'Address',\n",
    "    'CITY': 'City/Town',\n",
    "    'STATE': 'State',\n",
    "    'ZIP': 'ZIP Code'\n",
    "}, inplace=True)\n",
    "\n",
    "df1['ZIP Code'] = df1['ZIP Code'].astype(str)\n",
    "df2['ZIP Code'] = df2['ZIP Code'].astype(str)\n",
    "df3['ZIP Code'] = df3['ZIP Code'].astype(str)\n",
    "\n",
    "# Combine CMS datasets\n",
    "df2_df3_merged = pd.merge(df2, df3, on=['Address', 'City/Town', 'ZIP Code'], how='outer', suffixes=('_df2', '_df3'))\n",
    "for col in df2.columns:\n",
    "    if col in df3.columns and col not in ['Address', 'City/Town', 'ZIP Code']:\n",
    "        col_df2 = f\"{col}_df2\"\n",
    "        col_df3 = f\"{col}_df3\"\n",
    "        \n",
    "        if col_df2 in df2_df3_merged.columns and col_df3 in df2_df3_merged.columns:\n",
    "            # Where values are equal or one is NaN, fill NaN or keep one column\n",
    "            df2_df3_merged[col] = df2_df3_merged[col_df2].combine_first(df2_df3_merged[col_df3])\n",
    "            \n",
    "            # Drop the old columns with suffixes\n",
    "            df2_df3_merged.drop(columns=[col_df2, col_df3], inplace=True)\n",
    "\n",
    "# Fuzzy Matching Addresses Between df1 and df2_df3_merged\n",
    "def get_best_match(address, choices, threshold=85):\n",
    "    \"\"\"Find the best fuzzy match for an address.\"\"\"\n",
    "    match, score = process.extractOne(address, choices, scorer=fuzz.token_sort_ratio)\n",
    "    return match if score >= threshold else None\n",
    "\n",
    "address_choices = df2_df3_merged['Address'].dropna().unique()\n",
    "df1['Fuzzy_Matched_Address'] = df1['Address'].apply(lambda x: get_best_match(x, address_choices))\n",
    "\n",
    "# Combine all\n",
    "final_merge = pd.merge(df1, df2_df3_merged, left_on=['Fuzzy_Matched_Address', 'ZIP Code'],\n",
    "                       right_on=['Address', 'ZIP Code'], how='outer', suffixes=('_cms', '_hifld'))\n",
    "\n",
    "print(df1.count().max())\n",
    "print(df2.count().max())\n",
    "print(df3.count().max())\n",
    "print(final_merge.count().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c277779-8c33-441e-baa5-abc43180002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to consolidate primary values, ignoring 'Not Available'\n",
    "def consolidate(primary, alt1, alt2=None):\n",
    "    values = [primary, alt1, alt2]\n",
    "    # Filter out NaN and 'Not Available'\n",
    "    values = [v for v in values if pd.notna(v) and v != 'Not Available']\n",
    "    return values[0] if values else np.nan  # Return first valid value or NaN if none\n",
    "\n",
    "# Helper function to get alternatives, ignoring 'Not Available'\n",
    "def get_alternative(primary, alt1, alt2=None):\n",
    "    alternatives = []\n",
    "    for alt in [alt1, alt2]:\n",
    "        if pd.notna(alt) and alt != 'Not Available' and alt != primary:\n",
    "            alternatives.append(alt)\n",
    "        else:\n",
    "            alternatives.append(np.nan)\n",
    "    return alternatives[0]  # Return the first valid alternative, or NaN if none\n",
    "\n",
    "# Consolidate Facility Name\n",
    "final_merge['Facility Name'] = final_merge.apply(\n",
    "    lambda row: consolidate(row['Facility Name_cms'], row['Facility Name_hifld'], row['ALT_NAME']), axis=1)\n",
    "\n",
    "final_merge['Facility Name_alt'] = final_merge.apply(\n",
    "    lambda row: get_alternative(row['Facility Name'], row['Facility Name_hifld'], row['ALT_NAME']), axis=1)\n",
    "\n",
    "# Consolidate Address\n",
    "final_merge['Address'] = final_merge.apply(\n",
    "    lambda row: consolidate(row['Address_cms'], row['Address_hifld'], row['Fuzzy_Matched_Address']), axis=1)\n",
    "\n",
    "final_merge['Address_alt'] = final_merge.apply(\n",
    "    lambda row: get_alternative(row['Address'], row['Address_hifld'], row['Fuzzy_Matched_Address']), axis=1)\n",
    "\n",
    "# Consolidate City/Town\n",
    "final_merge['City/Town'] = final_merge.apply(\n",
    "    lambda row: consolidate(row['City/Town_cms'], row['City/Town_hifld']), axis=1)\n",
    "\n",
    "final_merge['City/Town_alt'] = final_merge.apply(\n",
    "    lambda row: get_alternative(row['City/Town'], row['City/Town_hifld']), axis=1)\n",
    "\n",
    "# Consolidate State\n",
    "final_merge['State'] = final_merge.apply(\n",
    "    lambda row: consolidate(row['State_cms'], row['State_hifld']), axis=1)\n",
    "\n",
    "final_merge['State_alt'] = final_merge.apply(\n",
    "    lambda row: get_alternative(row['State'], row['State_hifld']), axis=1)\n",
    "\n",
    "# Consolidate County\n",
    "final_merge['County'] = final_merge.apply(\n",
    "    lambda row: consolidate(row['County/Parish'], row['COUNTY']), axis=1)\n",
    "\n",
    "final_merge['County_alt'] = final_merge.apply(\n",
    "    lambda row: get_alternative(row['County'], row['COUNTY']), axis=1)\n",
    "\n",
    "# Keep ZIP Code and ZIP4 as is\n",
    "final_merge['ZIP Code'] = final_merge['ZIP Code'].fillna(final_merge['ZIP4'])\n",
    "\n",
    "final_merge.drop(columns=[col for col in final_merge.columns if col.endswith('_cms') or col.endswith('_hifld')], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4404d-acf2-457b-9b2a-3fd4de94c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge = final_merge[['OBJECTID', 'ID', 'Facility ID', 'Facility Name', 'Facility Name_alt',\n",
    "       'Address', 'Address_alt', 'City/Town', 'City/Town_alt', 'State',\n",
    "       'State_alt', 'County', 'County_alt', 'ZIP Code', 'ZIP4', 'TYPE',\n",
    "       'OWNER', 'Hospital Type', 'Hospital Ownership', 'STATUS', 'POPULATION',\n",
    "       'NAICS_CODE', 'NAICS_DESC', 'WEBSITE', 'TELEPHONE', 'TTL_STAFF', 'BEDS',\n",
    "       'TRAUMA', 'HELIPAD', 'Emergency Services',\n",
    "       'Meets criteria for birthing friendly designation',\n",
    "       'Hospital overall rating', 'Cesarean Birth', 'Elective Delivery',\n",
    "       'Exclusive Breast Milk Feeding',\n",
    "       'Risk Adjusted Severe Obstetric Complications (All)',\n",
    "       'Risk Adjusted Severe Obstetric Complications (excluding blood-transfusion-only cases)',\n",
    "       'LATITUDE', 'LONGITUDE', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4c3f7-b874-43a8-b427-b065f6d6a427",
   "metadata": {},
   "source": [
    "# Clean up Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655e931e-3d90-47f1-a535-de920917f976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ee9c5-828b-4c96-a183-f86232e7e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Up Coordinates\n",
    "df = final_merge\n",
    "def extract_coords(row):\n",
    "    if pd.isna(row['LATITUDE']) or pd.isna(row['LONGITUDE']):\n",
    "        if pd.notna(row['geometry']):\n",
    "            # Extract longitude and latitude from 'geometry' string (format: 'POINT (lon lat)')\n",
    "            lon, lat = row['geometry'].replace('POINT (', '').replace(')', '').split()\n",
    "            return pd.Series({'LATITUDE': float(lat), 'LONGITUDE': float(lon)})\n",
    "    return pd.Series({'LATITUDE': row['LATITUDE'], 'LONGITUDE': row['LONGITUDE']})\n",
    "\n",
    "# Apply extraction to fill missing LAT/LON\n",
    "df[['LATITUDE', 'LONGITUDE']] = df.apply(extract_coords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f13362-c6f1-4bc6-b7c2-7afdfd7cb20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize geocoder with a user agent\n",
    "geolocator = Nominatim(user_agent=\"hospital_locator\")\n",
    "\n",
    "# Function to build the full address string from available fields\n",
    "def build_full_address(row):\n",
    "    parts = [\n",
    "        row.get('Address') or row.get('Address_alt'), \n",
    "        row.get('City/Town') or row.get('City/Town_alt'),\n",
    "        row.get('County') or row.get('County_alt'),\n",
    "        row.get('State') or row.get('State_alt'),\n",
    "        row.get('ZIP Code') or row.get('ZIP4')\n",
    "    ]\n",
    "    # Filter out None or NaN values and join into a single string\n",
    "    return ', '.join([str(part) for part in parts if pd.notna(part)])\n",
    "\n",
    "# Function to geocode missing LATITUDE and LONGITUDE\n",
    "def geocode_missing(row):\n",
    "    if pd.isna(row['LATITUDE']) or pd.isna(row['LONGITUDE']):\n",
    "        full_address = build_full_address(row)\n",
    "        try:\n",
    "            location = geolocator.geocode(full_address, timeout=10)\n",
    "            if location:\n",
    "                return pd.Series({'LATITUDE': location.latitude, 'LONGITUDE': location.longitude})\n",
    "        except Exception as e:\n",
    "            print(f\"Error geocoding address: {full_address}, Error: {e}\")\n",
    "        # Return NaN if geocoding fails\n",
    "        return pd.Series({'LATITUDE': np.nan, 'LONGITUDE': np.nan})\n",
    "    return pd.Series({'LATITUDE': row['LATITUDE'], 'LONGITUDE': row['LONGITUDE']})\n",
    "\n",
    "# Apply geocoding to rows with missing coordinates\n",
    "df[['LATITUDE', 'LONGITUDE']] = df.apply(geocode_missing, axis=1)\n",
    "\n",
    "# Ensure rate limits are respected by pausing between requests\n",
    "time.sleep(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969cd7cd-57f9-4b53-95be-1e0c72aa48b7",
   "metadata": {},
   "source": [
    "# Baltimore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7670a68-605e-4d54-87f8-0683f268a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "from folium import FeatureGroup, LayerControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f58a28-6a3a-49e1-af9a-9698fa3134f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates for the center of Baltimore City\n",
    "baltimore_coords = (39.2904, -76.6122)\n",
    "\n",
    "# Function to calculate distance from Baltimore\n",
    "def within_15_miles(row):\n",
    "    if pd.notnull(row['LATITUDE']) and pd.notnull(row['LONGITUDE']):\n",
    "        hospital_coords = (row['LATITUDE'], row['LONGITUDE'])\n",
    "        distance = geodesic(baltimore_coords, hospital_coords).miles\n",
    "        return distance <= 15\n",
    "    return False\n",
    "\n",
    "bmore_df = df[df.apply(within_15_miles, axis=1)]\n",
    "bmore_df = bmore_df.dropna(subset=['LATITUDE', 'LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a809dc46-35e4-4298-905a-9560cf2297ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize the Map\n",
    "m = folium.Map(location=[39.2904, -76.6122], zoom_start=9.5)\n",
    "\n",
    "# Layer 1: Birthing Friendly Designation\n",
    "birthing_layer = FeatureGroup(name='Birthing Friendly Designation')\n",
    "for _, row in bmore_df.iterrows():\n",
    "    color = 'green' if row['Meets criteria for birthing friendly designation'] == 'Y' else 'red'\n",
    "    \n",
    "    popup_content = f\"\"\"\n",
    "    {row['Facility Name']}<br>\n",
    "    Birthing Friendly: {row['Meets criteria for birthing friendly designation']}<br>\n",
    "    Hospital Rating: {row['Hospital overall rating']}\n",
    "    \"\"\"\n",
    "\n",
    "    folium.Marker(\n",
    "        location=[row['LATITUDE'], row['LONGITUDE']],\n",
    "        popup=popup_content,\n",
    "        icon=folium.Icon(color=color)\n",
    "    ).add_to(birthing_layer)\n",
    "\n",
    "birthing_layer.add_to(m)\n",
    "\n",
    "\n",
    "# Add Custom Legend\n",
    "legend_html = '''\n",
    "<div style=\"position: fixed; \n",
    "     bottom: 50px; left: 50px; width: 200px; height: 90px; \n",
    "     background-color: white; z-index:9999; font-size:12px;\n",
    "     border:2px solid grey; border-radius:8px; padding: 10px;\">\n",
    "     <b>Birthing Friendly Hospital</b><br>\n",
    "     <i class=\"fa fa-map-marker fa-2x\" style=\"color:green\"></i> Yes<br>\n",
    "     <i class=\"fa fa-map-marker fa-2x\" style=\"color:red\"></i> No\n",
    "</div>\n",
    "'''\n",
    "\n",
    "m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "radius_meters = 15 * 1609.34\n",
    "\n",
    "folium.Circle(\n",
    "    location=baltimore_coords,\n",
    "    radius=radius_meters,\n",
    "    color='blue',\n",
    "    fill=True,\n",
    "    fill_opacity=0.1,\n",
    "    popup='15-Mile Radius from Baltimore'\n",
    ").add_to(m)\n",
    "\n",
    "# Add a marker for Baltimore center\n",
    "folium.Marker(\n",
    "    location=baltimore_coords,\n",
    "    popup='Baltimore City Center',\n",
    "    icon=folium.Icon(color='blue')\n",
    ").add_to(m)\n",
    "\n",
    "m.save('outputs/baltimore.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
